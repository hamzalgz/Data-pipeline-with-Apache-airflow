{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c5a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from airflow.contrib.hooks.fs_hook import FSHook\n",
    "#\n",
    "# from airflow.contrib.sensors.file_sensor import FileSensor\n",
    "from airflow.operators.dummy_operator    import DummyOperator\n",
    "from airflow.operators.python_operator    import PythonOperator\n",
    "from airflow.operators.trigger_dagrun import  TriggerDagRunOperator\n",
    "\n",
    "#file place in /data/ds_env/..../packages-site/\n",
    "from omega_plugin_file import OmegaFileSensor, ArchiveFileOperator\n",
    "\n",
    "#installed using pip (check pip freez)\n",
    "from airflow.providers.papermill.operators.papermill import PapermillOperator\n",
    "\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "import airflow\n",
    "\n",
    "\n",
    "\n",
    "default_args = {\n",
    "    \"depends_on_past\" : False,\n",
    "    \"start_date\"      : airflow.utils.dates.days_ago( 1 ),\n",
    "    \"retries\"         : 1,\n",
    "    \"retry_delay\"     : datetime.timedelta( hours= 5 ),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "task_name = 'check_file'\n",
    "\n",
    "def print_filename(**context):\n",
    "  file_to_process = context['task_instance'].xcom_pull(key='file_name', task_ids=\"check_new_file\")\n",
    "  print(\"->>>> we will save this file : \",file_to_process)\n",
    "  file = open(\"/home/imade/notebook/input_config.txt\",\"w\")\n",
    "  file.write(file_to_process)\n",
    "  file.close()\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "with airflow.DAG( \"first_etl\", default_args= default_args, schedule_interval= \"@once\"  ) as dag:\n",
    "    start_task  = DummyOperator(  task_id= \"start\" )\n",
    "    stop_task   = DummyOperator(  task_id= \"stop\"  )\n",
    "    \n",
    "    \n",
    "    \n",
    "    #using the defined OmegaFileSensor operator to check for new files\n",
    "    sensor_task = OmegaFileSensor(\n",
    "      task_id='check_new_file', #name of the task\n",
    "      filepath=\"/home/imade/notebook/input/\", #root path for checking\n",
    "      filepattern=r\"\\b(\\w*.xlsx)\", #pattern used when checking domaine/date/file_json\n",
    "      poke_interval=10, #time interval between file verification\n",
    "      dag=dag #append task to dag\n",
    "    )\n",
    "    \n",
    "    preparing_detected_file = PythonOperator(\n",
    "      task_id=\"preparing_detected_file\",\n",
    "      python_callable=print_filename,\n",
    "      #provide_context=True,\n",
    "      retries=10,\n",
    "      retry_delay=datetime.timedelta(seconds=1)\n",
    "    )\n",
    "    \n",
    "    \n",
    "   \n",
    "    process_file_notebook = PapermillOperator(\n",
    "        task_id=\"process_file_notebook\",\n",
    "        input_nb=\"/home/imade/notebook/process_input_list.ipynb\",\n",
    "        output_nb=\"/home/imade/notebook//outs/out-process_input_list{{ execution_date }}.ipynb\",\n",
    "        parameters={\"msgs\": \"Ran from Airflow at {{ execution_date }}!\"},\n",
    "    )    \n",
    "    \n",
    "    trigger_again = TriggerDagRunOperator(\n",
    "        task_id='trigger_dag_again', \n",
    "        trigger_dag_id=\"first_etl\", \n",
    "        dag=dag\n",
    "    )\n",
    "   \n",
    "start_task >> sensor_task >> preparing_detected_file >> process_file_notebook >> stop_task >> trigger_again"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
